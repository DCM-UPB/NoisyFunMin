\documentclass[11pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{makeidx}
\usepackage[usenames,dvipsnames]{color}
\usepackage[unicode=true,colorlinks=true,linkcolor=RoyalBlue,citecolor=RoyalBlue]{hyperref}
\usepackage{natbib}
\usepackage{lipsum}

\title{The NoisyFunOpt C++ Library}
\author{Francesco Calcavecchia}

\makeindex

\newcommand{\MRTWO}{$ \text{M}(\text{RT})^2 \;$}


\begin{document}
\maketitle

NoisyFunOpt is a C++ library that contains simple tools for optimising (minimize) a noisy function, e.g. an integral computed with the Monte Carlo technique.
It currently supports only the Conjugate Gradient algorithm, with some minor modifications made to handle the noise.
More specifically, two function values \verb+a+ and \verb+b+ with associated standard deviations \verb+da+ and \verb+db+ are considered to be:
\begin{itemize}
   \item $\verb+a+ > \verb+b+ \quad $ iff $ \quad \verb+a+ - 2 \verb+da+ > \verb+b+ - 2 \verb+db+$;
   \item $\verb+a+ < \verb+b+ \quad $ iff $ \quad \verb+a+ + 2 \verb+da+ < \verb+b+ + 2 \verb+db+$;
   \item $\verb+a+ = \verb+b+ \quad $ otherwise.
\end{itemize}

The code has been developed using the standard C++11.

In the following we will present the classes made available by the library.
At the beginning we will report the necessary \verb+#include+ call and the prototype of the class.
The comment \verb+TO DO+ indicates that the method needs to be implemented (as in the case of a pure virtual class).


\section{NoisyFunction}
\label{sec:NoisyFunction}

\begin{verbatim}
\\ #include "NoisyFunction.hpp"
class NoisyFunction
{
   NoisyFunction(int);
   virtual ~NoisyFunction();
   
   int getNDim();
   
   virtual void f(const double *, double &, double &) = 0;  \\ TO DO
};
\end{verbatim}

A \verb+NoisyFunction+ implements a function $f:\mathbb{R}^{n} \rightarrow \mathbb{R} \times \mathbb{R}$ which takes a multidimensional vector as input, and returns a scalar value with an associated error bar. 

\begin{itemize}
   \item \verb+NoisyFunction(int ndim)+: The constructor. \verb+ndim+ must contains the value of $n$, i.e. the number of dimensions of the input;
   \item \verb+~NoisyFunction()+: Virtual destructor. It does nothing;
   \item \verb+getNDim()+: It returns the \verb+ndim+ provided with the constructor;
   \item \verb+f(const double *x, double &val, double &dval)+: The implementation of $f$. It takes an array \verb+x+ as input and returns in \verb+val+ the value of the function and in \verb+dval+ the error bar associated with it.
\end{itemize}

% section NoisyFunction (end)



\section{NoisyFunctionWithGradient} % (fold)
\label{sec:NoisyFunctionWithGradient}

\begin{verbatim}
\\ #include "NoisyFunction.hpp"
class NoisyFunctionWithGradient: public NoisyFunction
{
   NoisyFunctionWithGradient(int);
   virtual ~NoisyFunctionWithGradient();
   
   virtual void grad(const double *, double *, double *) = 0; // TO DO
};
\end{verbatim}

\verb+NoisyFunctionWithGradient+ is a child class of \verb+NoisyFunction+ (therefore the implementation of the method \verb+f+ is required), and its aim is to generalize the class to the case in which the gradient of $f$ is known.

\begin{itemize}
   \item \verb+NoisyFunctionWithGradient(int ndim)+: The constructor. As in \verb+NoisyFunction+;
   \item \verb+~NoisyFunctionWithGradient()+: The destructor. It does nothing;
   \item \verb+grad(const double *x, double *grad, double *dgrad)+: The gradient of $f$. It takes \verb+x+ as input, and returns the gradient in \verb+grad+ and the corresponding errors in \verb+dgrad+.
\end{itemize}

% section NoisyFunctionWithGradient (end)



\section{NFM} % (fold)
\label{sec:nfm}

\begin{verbatim}
// #include "NoisyFunMin.hpp"
class NFM{
   NFM(NoisyFunction *);                                       
   virtual ~NFM();
   
   void setX(const double *);
   void setGradientTargetFun(NoisyFunctionWithGradient *);          
   void setEpsTargetFun(double &); 
   void setEpsX(double &);                          
   
   int getNDim();                                         
   double getX(const int &);                    
   void getX(double * x);
   double getF();                             
   double getDf();                  
   NoisyFunctionWithGradient* getGradientTargetFun(); 
   double getEpsTargetFun();            
   double getEpsX();
   
   virtual void findMin() = 0; // TO DO
};
  
\end{verbatim}

\verb+NFM+ is an interface for a generic minimisation method.
Any actual implementation of this interface will have to specify the \verb+findMin+ method.

The minimisation process will start from a point \verb+x+, set with the method \verb+setX+, and wil continue until the minimum has been found.
At the end of this process, \verb+x+ will have to be in this minimum.

\begin{itemize}
   \item \verb+NFM(NoisyFunction *f)+: The constructor. It takes as input a target function \verb+f+;
   \item \verb+~NFM()+: The destructor. It does nothing;
   \item \verb+setX(const double *x)+: Set the starting point of the minimisator. By default it is set equal to $0$;
   \item \verb+setGradientTargetFun(NoisyFunctionWithGradient * grad)+: Set a target function with gradient;
   \item \verb+setEpsTargetFun(double &eps)+: Set the value of the minimum change in the target function value that will make continue the minimisation process. This parameter might be irrelevant, depending on the actual implementation of the minimisation algorithm;
   \item \verb+setEpsX(double &eps)+: Set the value of the minimum change in the minimum point that will make continue the minimisation process. This parameter might be irrelevant, depending on the actual implementation of the minimisation algorithm;
   \item \verb+getNDim()+: It returns the number of dimensions of the space in which the function is minimised;
   \item \verb+getX(const int &i)+: It returns the \verb+i+-th coordinate of the actual position of \verb+x+, which will coincide with the minimum after the minimisation process;
   \item \verb+getF()+: It returns the value of $f$ in \verb+x+;
   \item \verb+getDf()+: It returns the error bar associated with the value of $f(\verb+x+)$;
   \item \verb+getGradientTargetFun()+: It returns the pointer to the target function with gradient, if there is one. Otherwise returns \verb+0+;
   \item \verb+getEpsTargetFun()+: It returns the value set with \verb+setEpsTargetFun+, which is $0$ by default;
   \item \verb+getEpsX()+: It returns the value set with \verb+setEpsX+, which is $0$ by default;
   \item \verb+findMin()+: The minimisation subroutine. At the end of this process, \verb+x+ is supposed to be in the minimum of the target function. Therefore, after calling this method, it will be possible to know where the minimum is by using the method \verb+getX+, while its corresponding value and error bar will be directly accessible with \verb+getF+ and \verb+getDf+.
\end{itemize}

% section nfm (end)



\section{ConjGrad} % (fold)
\label{sec:conjgrad}

\begin{verbatim}
\\ #include "ConjGrad.hpp"
class ConjGrad: public NFM
{
   ConjGrad(NoisyFunctionWithGradient *);
   ~ConjGrad();   
};
\end{verbatim}

Implementation of the Conjugate Gradient algorithm, using the \emph{Para-Gold Search} method for the one-dimensional minimisation (see https://publications.ub.uni-mainz.de/theses/volltexte/2014/3805/pdf/3805.pdf, page 61).

\begin{itemize}
   \item \verb+ConjGrad(NoisyFunctionWithGradient *f)+: The constructor. It takes as input the target function \verb+f+;
   \item \verb+~ConjGrad()+: The destructor. It does nothing;
\end{itemize}

% section conjgrad (end)



\printindex

\end{document}