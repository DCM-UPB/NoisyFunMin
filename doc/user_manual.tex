\documentclass[11pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{makeidx}
\usepackage[usenames,dvipsnames]{color}
\usepackage[unicode=true,colorlinks=true,linkcolor=RoyalBlue,citecolor=RoyalBlue]{hyperref}
\usepackage{natbib}
\usepackage{lipsum}

% C++ formatting
\usepackage{listings}  % for code formatting
\usepackage{color}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
  backgroundcolor=\color{lbcolor},
  tabsize=4,
  language=C++,
  captionpos=b,
  tabsize=3,
  frame=lines,
  numbers=left,
  numberstyle=\tiny,
  numbersep=5pt,
  breaklines=true,
  showstringspaces=false,
  basicstyle=\footnotesize,
  identifierstyle=\color{magenta},
  keywordstyle=\color[rgb]{0,0,1},
  commentstyle=\color{OliveGreen},
  stringstyle=\color{red}
}




\title{The NoisyFunOpt C++ Library}
\author{Francesco Calcavecchia}

\makeindex

\newcommand{\MRTWO}{$ \text{M}(\text{RT})^2 \;$}


\begin{document}
\maketitle

NoisyFunOpt is a C++ library that contains simple tools to optimise (minimize) a noisy function, e.g. an integral computed with the Monte Carlo technique.
More specifically, two function values \verb+a+ and \verb+b+ with associated standard deviations \verb+da+ and \verb+db+ are considered to be:
\begin{itemize}
\item $\verb+a+ > \verb+b+ \quad $ iff $ \quad \verb+a+ - 2 \verb+da+ > \verb+b+ + 2 \verb+db+$;
\item $\verb+a+ < \verb+b+ \quad $ iff $ \quad \verb+a+ + 2 \verb+da+ < \verb+b+ - 2 \verb+db+$;
\item $\verb+a+ = \verb+b+ \quad $ otherwise.
\end{itemize}

The code has been developed using the standard C++11.

In the following we will present the classes made available by the library.
At the beginning we will report the necessary \verb+#include+ call and the prototype of the class.
The comment \verb+TO DO+ indicates that the method needs to be implemented (as in the case of a pure virtual class).


\section{NoisyFunction}
\label{sec:NoisyFunction}

\begin{lstlisting}
\\ #include "NoisyFunction.hpp"
class NoisyFunction
{
   NoisyFunction(int);
   virtual ~NoisyFunction();

   int getNDim();

   virtual void f(const double *, double &, double &) = 0;  \\ TO DO
};
\end{lstlisting}

A \verb+NoisyFunction+ implements a function $f:\mathbb{R}^{n} \rightarrow \mathbb{R} \times \mathbb{R}$ which takes a multidimensional vector as input, and returns a scalar value with an associated error bar.

\begin{itemize}
\item \verb+NoisyFunction(int ndim)+: The constructor. \verb+ndim+ must contains the value of $n$, i.e. the number of dimensions of the input;
\item \verb+~NoisyFunction()+: Virtual destructor. It does nothing;
\item \verb+getNDim()+: It returns the \verb+ndim+ provided with the constructor;
\item \verb+f(const double *x, double &val, double &dval)+: The implementation of $f$. It takes an array \verb+x+ as input and returns in \verb+val+ the value of the function and in \verb+dval+ the error bar associated with it.
\end{itemize}

% section NoisyFunction (end)



\section{NoisyFunctionWithGradient} % (fold)
\label{sec:NoisyFunctionWithGradient}

\begin{lstlisting}
\\ #include "NoisyFunction.hpp"
class NoisyFunctionWithGradient: public NoisyFunction
{
   NoisyFunctionWithGradient(int);
   virtual ~NoisyFunctionWithGradient();

   virtual void grad(const double *, double *, double *) = 0; // TO DO
};
\end{lstlisting}

\verb+NoisyFunctionWithGradient+ is a child class of \verb+NoisyFunction+ (therefore the implementation of the method \verb+f+ is required), and it aims to cover the cases in which the gradient of $f$ is known.

\begin{itemize}
\item \verb+NoisyFunctionWithGradient(int ndim)+: The constructor. As in \verb+NoisyFunction+;
\item \verb+~NoisyFunctionWithGradient()+: The destructor. It does nothing;
\item \verb+grad(const double *x, double *grad, double *dgrad)+: The gradient of $f$. It takes \verb+x+ as input, and returns the gradient in \verb+grad+ and the corresponding errors in \verb+dgrad+.
\end{itemize}

% section NoisyFunctionWithGradient (end)



\section{NFM} % (fold)
\label{sec:nfm}

\begin{lstlisting}
// #include "NoisyFunMin.hpp"
class NFM{
   NFM(NoisyFunction *);
   virtual ~NFM();

   void setX(const double *);
   void setX(const int &, const double &);
   void setGradientTargetFun(NoisyFunctionWithGradient *);
   void setEpsTargetFun(double &);
   void setEpsX(double &);

   int getNDim();
   double getX(const int &);
   void getX(double * x);
   double getF();
   double getDf();
   NoisyFunctionWithGradient* getGradientTargetFun();
   double getEpsTargetFun();
   double getEpsX();

   virtual void findMin() = 0; // TO DO
};

\end{lstlisting}

\verb+NFM+ is an interface for a generic minimisation method.
Any actual implementation of this interface will have to specify the \verb+findMin+ method.

The minimisation process will start from a point \verb+x+, set with the method \verb+setX+, and wil continue until the minimum has been found.
At the end of this process, \verb+x+ will have to be in this minimum and will be accessible with the method \verb+getX+.

\begin{itemize}
\item \verb+NFM(NoisyFunction *f)+: The constructor. It takes as input a target function \verb+f+;
\item \verb+~NFM()+: The destructor. It does nothing;
\item \verb+setX(const double *x)+: Set the starting point of the minimisator. By default it is set equal to $0$;
\item \verb+setX(const int &, const double &)+: Like above, but set only one \verb+x+ according to index.
\item \verb+setGradientTargetFun(NoisyFunctionWithGradient * grad)+: Set a target function with gradient, in case it is available and/or the actual implementation of NFM requires it;
\item \verb+setEpsTargetFun(double &eps)+: Set the value of the minimum change in the target function value that will make continue the minimisation process. This parameter might be irrelevant, depending on the actual implementation of the minimisation algorithm;
\item \verb+setEpsX(double &eps)+: Set the value of the minimum change in the minimum point that will make continue the minimisation process. This parameter might be irrelevant, depending on the actual implementation of the minimisation algorithm;
\item \verb+getNDim()+: It returns the number of dimensions of the space in which the function is minimised;
\item \verb+getX(const int &i)+: It returns the \verb+i+-th coordinate of the actual position of \verb+x+, which will coincide with the minimum after the minimisation process;
\item \verb+getF()+: It returns the value of $f$ in \verb+x+;
\item \verb+getDf()+: It returns the error bar associated with the value of $f(\verb+x+)$;
\item \verb+getGradientTargetFun()+: It returns the pointer to the target function with gradient, if there is one. Otherwise returns \verb+0+;
\item \verb+getEpsTargetFun()+: It returns the value set with \verb+setEpsTargetFun+, which is $0$ by default;
\item \verb+getEpsX()+: It returns the value set with \verb+setEpsX+, which is $0$ by default;
\item \verb+findMin()+: The minimisation subroutine. At the end of this process, \verb+x+ is supposed to be in the minimum of the target function. Therefore, after calling this method, it will be possible to know where the minimum is by using the method \verb+getX+, while its corresponding value and error bar will be directly accessible with \verb+getF+ and \verb+getDf+.
\end{itemize}

% section nfm (end)




\section{Log report} % (fold)
\label{sec:log_output}

It is possible to activate the log report for following the algorithm internal dynamic.
To do so, simply use the following commands:

\begin{lstlisting}
\\ #include "LogNFM.hpp"

NFMLogManager log;
log.setLoggingOn();
\end{lstlisting}

This will automatically output the log messages on the stdout (i.e. print on screen).
It is possible to make it write it on a file instead.
To do so:

\begin{lstlisting}
log.setLoggingPathFile("NFM.log");
\end{lstlisting}

Finally, it is possible to interrupt the log output in any moment using the command
\begin{lstlisting}
log.setLoggingOff();
\end{lstlisting}
and to explicitly write a message in the log report
\begin{lstlisting}
log.writeOnLog("message to write on the log");
\end{lstlisting}

% section log_output (end)



\section{ConjGrad} % (fold)
\label{sec:conjgrad}

\begin{lstlisting}
\\ #include "ConjGrad.hpp"
class ConjGrad: public NFM
{
   ConjGrad(NoisyFunctionWithGradient *);
   ~ConjGrad();

   void configureToFollowSimpleGradient()
};
\end{lstlisting}

Implementation of the Conjugate Gradient algorithm, using the \emph{Para-Gold Search} method for the one-dimensional minimisation (see https://publications.ub.uni-mainz.de/theses/volltexte/2014/3805/pdf/3805.pdf, page 61).

It requires a \verb+NoisyFunctionWithGradient+ for running.

\begin{itemize}
\item \verb+ConjGrad(NoisyFunctionWithGradient *f)+: The constructor. It requires an input target function with gradient \verb+f+;
\item \verb+~ConjGrad()+: The destructor. It does nothing;
\item \verb+configureToFollowSimpleGradient()+: It asks the algorithm to ignore computing the conjugate gradient, but rather use the simple gradient. Needless to say, this method should be called before the subroutine \verb+findMin+;
\end{itemize}

% section conjgrad (end)




\section{DynamicDescent} % (fold)
\label{sec:dynamicdescent}

\begin{lstlisting}
\\ #include "DynamicDescent.hpp"
class DynamicDescent: public NFM
{
   DynamicDescent(NoisyFunctionWithGradient * targetfun, bool useGradientError = false, size_t &max_n_const_values = 20);
   ~DynamicDescent();
};
\end{lstlisting}

This implementation is extremely simple, however it can be useful in certain circumstances. To minimise the function it uses the gradient (actually $-\nabla$) of the function as direction for moving. For deciding "how much" to move in that direction, it multiplies the gradient with a scalar value $\lambda$ (named \verb+_inertia+ in the code) set in the following way:
\begin{enumerate}
\item $\lambda_0 \equiv \frac{Ndim}{\left| \nabla_0 \right|}$ at the first step;
\item $\lambda_{i+1} = \lambda_i + \frac{1}{2} \lambda_i <\nabla_{i+1}, \nabla_i>$ ($< \dots >$ symbolises a scalar product) at any other step;
\end{enumerate}
This iterative procedure should ensure that when we are far from the minimum and we keep moving in the same direction, $lambda$ grows, whereas when we are close to the minimum, and the direction keeps changing, $lambda$ is quickly reduced to almost zero.

The aforementioned iterative procedure stops when the last \verb+max_n_const_values+ (default to $20$) points found are equal, meaning that the procedure has stabilised around a minimum. If \verb+useGradientError+ is \verb+true+, the optimization will also terminate when all gradient elements are smaller than their respective errors.

\begin{itemize}
\item \verb+DynamicDescent(NoisyFunctionWithGradient *f)+: The constructor. It requires an input target function with gradient \verb+f+;
\item \verb+~DynamicDescent()+: The destructor. It does nothing;
\end{itemize}

% section dynamicdescent (end)


\section{Adam} % (fold)
\label{sec:adam}

\begin{lstlisting}
\\ #include "Adam.hpp"
class Adam: public NFM
{
   Adam(NoisyFunctionWithGradient * targetfun, bool useGradientError = false, size_t &max_n_const_values = 20, double &alpha = 0.001, double &beta1 = 0.9, double &beta2 = 0.999, double &epsilon = 10e-8);
};
\end{lstlisting}

This is an implementation of the popular Adam minimization algorithm (https://arxiv.org/pdf/1412.6980.pdf). The article provides reference for algorithm and parameters above, which have the same names as in the paper.
\\\\The optimizer requires a gradient, but no error terms on that. The procedure stops on convergence, handled in the same way as in DynamicDescent. 

% section adam (end)

\printindex

\end{document}
